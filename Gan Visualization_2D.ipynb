{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(2, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 2), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.hidden_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(2, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 1), \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.hidden_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from real distribution, let assume it is gaussian distribution where mean is 5, var is 1\n",
    "def draw_from_real(size):\n",
    "    xs = np.random.normal(loc=1.0, scale=0.5, size=size)\n",
    "    ys = np.random.normal(loc=0.0, scale=1.5, size=size)\n",
    "    real_data = np.array(list(zip(xs, ys)))\n",
    "    return real_data\n",
    "\n",
    "# noise is uniform distibution in [-10, 10]\n",
    "def draw_from_noise(size):\n",
    "    noise_xs = np.random.uniform(low=-10.0, high=10.0, size=size)\n",
    "    noise_ys = np.random.uniform(low=-10.0, high=10.0, size=size)\n",
    "    noise = np.array(list(zip(noise_xs, noise_ys)))\n",
    "    return noise\n",
    "\n",
    "# Get data from generator, where input generator is noise\n",
    "def draw_from_fake(generator, size):\n",
    "    noises = draw_from_noise(size)\n",
    "    with torch.no_grad():\n",
    "        noises = draw_from_noise(size)\n",
    "        noises = torch.from_numpy(noises) # Conver numpy to tensor\n",
    "        noises = Variable(noises.type(Tensor)).view(size, -1)\n",
    "        fake_datas = generator(noises)\n",
    "        fake_datas = fake_datas.data.numpy()\n",
    "    return fake_datas\n",
    "\n",
    "real_data = draw_from_real(1000)\n",
    "def plot_scatter(generator, discriminator, save_path=None, title=None):\n",
    "    \n",
    "    if title == 'generator':\n",
    "        global fake_data\n",
    "        fake_data = draw_from_fake(generator, 1000)\n",
    "    xs, ys = [data[0] for data in real_data], [data[1] for data in real_data]\n",
    "    plt.scatter(xs, ys, c='red', s=3, label='Real')\n",
    "    xs, ys = [data[0] for data in fake_data], [data[1] for data in fake_data]\n",
    "    plt.scatter(xs, ys, c='blue', s=3, label='Fake')\n",
    "    \n",
    "    plt.xlim(-5,5)\n",
    "    plt.ylim(-5,5)\n",
    "\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    y = np.linspace(-5, 5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    sample_points = np.array(list(zip(X.reshape(100*100), Y.reshape(100*100))))\n",
    "    datas = torch.from_numpy(sample_points) # Conver numpy to tensor\n",
    "    datas = Variable(datas.type(Tensor)).view(-1, 2)\n",
    "    with torch.no_grad():\n",
    "        datas = torch.from_numpy(sample_points) # Conver numpy to tensor\n",
    "        datas = Variable(datas.type(Tensor)).view(-1, 2)\n",
    "        output = discriminator(datas)\n",
    "    \n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    y = np.linspace(-5, 5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    sample_points = np.array(list(zip(X.reshape(100*100), Y.reshape(100*100))))\n",
    "    datas = torch.from_numpy(sample_points) # Conver numpy to tensor\n",
    "    datas = Variable(datas.type(Tensor)).view(-1, 2)\n",
    "    with torch.no_grad():\n",
    "        datas = torch.from_numpy(sample_points) # Conver numpy to tensor\n",
    "        datas = Variable(datas.type(Tensor)).view(-1, 2)\n",
    "        output = discriminator(datas)\n",
    "    Z = output.data.numpy().reshape((100,100))\n",
    "    plt.contourf(X, Y, Z, 20, cmap='copper', alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.clf()\n",
    "        return\n",
    "    plt.show()\n",
    "    \n",
    "# plot_density(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Network \n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "fake_data = draw_from_fake(generator, 10000)\n",
    "\n",
    "# Optimizers\n",
    "lr = 0.0002\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D Loss:1.3299] [G Loss:0.6348]\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "d_loss_total = 0\n",
    "g_loss_total = 0\n",
    "\n",
    "d_step = 10\n",
    "g_step = 10\n",
    "\n",
    "num_iters = 1000\n",
    "\n",
    "cnt = 0\n",
    "for iter_ in range(num_iters):\n",
    "    real_label = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "    fake_label = Variable(Tensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "    \n",
    "    # --------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "    for i in range(d_step):\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # compute loss for real data (discrimator should output 1)\n",
    "        real_datas = draw_from_real(batch_size)\n",
    "        real_datas = torch.from_numpy(real_datas) # Conver numpy to tensor\n",
    "        real_datas = Variable(real_datas.type(Tensor)).view(batch_size, -1)\n",
    "\n",
    "        real_output = discriminator(real_datas)\n",
    "        real_loss = adversarial_loss(real_output, real_label)\n",
    "        real_loss.backward()\n",
    "\n",
    "        # computer loss for fake data (discrimator should ouput 0)\n",
    "        noises = draw_from_noise(batch_size)\n",
    "        noises = torch.from_numpy(noises) # Conver numpy to tensor\n",
    "        noises = Variable(noises.type(Tensor)).view(batch_size, -1)\n",
    "        fake_datas = generator(noises)\n",
    "\n",
    "        fake_output = discriminator(fake_datas.detach()) # don't propagate to generator net\n",
    "        fake_loss = adversarial_loss(fake_output, fake_label)\n",
    "        fake_loss.backward()\n",
    "\n",
    "        # compute total loss and update weight \n",
    "        discriminator_loss = real_loss + fake_loss\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        if i % (d_step//10+1) == 0:\n",
    "            plot_scatter(generator, discriminator, save_path='./Result/2D/%d.jpg'%(cnt), title='discriminator')\n",
    "            cnt += 1\n",
    "    \n",
    "    d_loss_total += discriminator_loss.item()\n",
    "        \n",
    "    # -----------------\n",
    "    #  Train Generator\n",
    "    # -----------------\n",
    "    for i in range(g_step):\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # computer loss for fake data (discrimator should ouput 1)\n",
    "        noises = draw_from_noise(batch_size)\n",
    "        noises = torch.from_numpy(noises) # Conver numpy to tensor\n",
    "        noises = Variable(noises.type(Tensor)).view(batch_size, -1)\n",
    "        fake_datas = generator(noises)\n",
    "\n",
    "        fake_output = discriminator(fake_datas)\n",
    "        generator_loss = adversarial_loss(fake_output, real_label)\n",
    "        generator_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        if i % (g_step//10+1) == 0:\n",
    "            plot_scatter(generator, discriminator, save_path='./Result/2D/%d.jpg'%(cnt), title='generator')\n",
    "            cnt += 1\n",
    "            \n",
    "    if iter_ % (num_iters//10) == 0:\n",
    "        g_loss_total += generator_loss.item()\n",
    "        print(\"[D Loss:%.4f] [G Loss:%.4f]\"%(d_loss_total/(iter_+1), g_loss_total/(iter_+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "def clear_data():\n",
    "    for img_path in glob.glob('./Result/2D/*.jpg'):\n",
    "        os.remove(img_path)\n",
    "clear_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
